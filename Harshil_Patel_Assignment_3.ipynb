{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "92778525",
      "metadata": {
        "id": "92778525"
      },
      "source": [
        "# Assignment 3: Non-Linear Models and Validation Metrics (37 total marks)\n",
        "### Due: October 24 at 11:59pm\n",
        "\n",
        "### Name: Harshil Patel"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce31b39a",
      "metadata": {
        "id": "ce31b39a"
      },
      "source": [
        "### In this assignment, you will need to write code that uses non-linear models to perform classification and regression tasks. You will also be asked to describe the process by which you came up with the code. More details can be found below. Please cite any websites or AI tools that you used to help you with this assignment."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf275ca7",
      "metadata": {
        "id": "cf275ca7"
      },
      "source": [
        "### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "2b67a661",
      "metadata": {
        "id": "2b67a661"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from yellowbrick.regressor import ResidualsPlot\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.metrics import confusion_matrix, classification_report"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ee2d2c3",
      "metadata": {
        "id": "5ee2d2c3"
      },
      "source": [
        "## Part 1: Regression (14.5 marks)\n",
        "\n",
        "For this section, we will be continuing with the concrete example from yellowbrick. You will need to compare these results to the results from the previous assignment. Please use the results from the solution if you were unable to complete Assignment 2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8219f163",
      "metadata": {
        "id": "8219f163"
      },
      "source": [
        "### Step 1: Data Input (0.5 marks)\n",
        "\n",
        "The data used for this task can be downloaded using the yellowbrick library:\n",
        "https://www.scikit-yb.org/en/latest/api/datasets/concrete.html\n",
        "\n",
        "Use the yellowbrick function `load_concrete()` to load the concrete dataset into the feature matrix `X` and target vector `y`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "2af8bd32",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2af8bd32",
        "outputId": "3bbd4472-b647-4aca-e958-b9243b51c306"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X (features): (1030, 8)\n",
            "Shape of y (target): (1030,)\n"
          ]
        }
      ],
      "source": [
        "# Import the necessary libraries from Yellowbrick and load_concrete dataset\n",
        "import yellowbrick\n",
        "from yellowbrick.datasets import load_concrete\n",
        "\n",
        "# Load the concrete dataset into X (features) and y (target)\n",
        "X, y = load_concrete()\n",
        "\n",
        "# Print the shape of the feature matrix X\n",
        "print(\"Shape of X (features):\", X.shape)\n",
        "\n",
        "# Print the shape of the target vector y\n",
        "print(\"Shape of y (target):\", y.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42fea4cc",
      "metadata": {
        "id": "42fea4cc"
      },
      "source": [
        "### Step 2: Data Processing (0 marks)\n",
        "\n",
        "Data processing was completed in the previous assignment. No need to repeat here."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a245d00",
      "metadata": {
        "id": "2a245d00"
      },
      "source": [
        "### Step 3: Implement Machine Learning Model\n",
        "\n",
        "1. Import the Decision Tree, Random Forest and Gradient Boosting Machines regression models from sklearn\n",
        "2. Instantiate the three models with `max_depth = 5`. Are there any other parameters that you will need to set?\n",
        "3. Implement each machine learning model with `X` and `y`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f994e31",
      "metadata": {
        "id": "3f994e31"
      },
      "source": [
        "### Step 4: Validate Model\n",
        "\n",
        "Calculate the average training and validation accuracy using mean squared error with cross-validation. To do this, you will need to set `scoring='neg_mean_squared_error'` in your `cross_validate` function and negate the results (multiply by -1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5fc3f7a8",
      "metadata": {
        "id": "5fc3f7a8"
      },
      "source": [
        "### Step 5: Visualize Results (4 marks)\n",
        "\n",
        "1. Create a pandas DataFrame `results` with columns: Training accuracy and Validation accuracy, and index: DT, RF and GB\n",
        "2. Add the accuracy results to the `results` DataFrame\n",
        "3. Print `results`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "fdc93a78",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdc93a78",
        "outputId": "8504183f-f53b-4b4f-d126-2600c14d64f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Training MSE Validation MSE\n",
            "DT    73.929864      69.812835\n",
            "RF     28.27354      20.847017\n",
            "GB    27.920575      24.899703\n"
          ]
        }
      ],
      "source": [
        "# TO DO: ADD YOUR CODE HERE FOR STEPS 3-5\n",
        "# Note: for any random state parameters, you can use random_state = 0\n",
        "# HINT: USING A LOOP TO STORE THE DATA IN YOUR RESULTS DATAFRAME WILL BE MORE EFFICIENT\n",
        "\n",
        "# Import necessary libraries and modules\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import pandas as pd\n",
        "\n",
        "# Split the dataset into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "# Define a dictionary of regression models to be evaluated\n",
        "models = {\n",
        "    \"DT\": DecisionTreeRegressor(max_depth=5),\n",
        "    \"RF\": RandomForestRegressor(n_estimators=100),\n",
        "    \"GB\": GradientBoostingRegressor(n_estimators=100, learning_rate=0.1)\n",
        "}\n",
        "\n",
        "# Create an empty DataFrame to store results with model names as columns\n",
        "results = pd.DataFrame(columns=[\"Training MSE\", \"Validation MSE\"], index=models.keys())\n",
        "\n",
        "# Loop through each model and evaluate its performance\n",
        "for model_name, model in models.items():\n",
        "    # Evaluate the model's performance using cross-validation on the training data\n",
        "    train_scores = cross_val_score(model, X_train, y_train, cv=5, scoring=\"neg_mean_squared_error\")\n",
        "    train_mse = -train_scores.mean()  # Calculate mean squared error (MSE) from negative scores\n",
        "\n",
        "    # Fit the model on the training data\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the validation set and calculate the validation MSE\n",
        "    y_val_pred = model.predict(X_val)\n",
        "    val_mse = mean_squared_error(y_val, y_val_pred)\n",
        "\n",
        "    # Store the training and validation MSE in the results DataFrame\n",
        "    results.loc[model_name, \"Training MSE\"] = train_mse\n",
        "    results.loc[model_name, \"Validation MSE\"] = val_mse\n",
        "\n",
        "# Print the results DataFrame showing training and validation MSE for each model\n",
        "print(results)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31715a9d",
      "metadata": {
        "id": "31715a9d"
      },
      "source": [
        "Repeat the step above to print the R2 score instead of the mean-squared error. For this case, you can use `scoring='r2'`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "83539f47",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83539f47",
        "outputId": "507767f9-76e2-443a-eb6c-5aa331a01453"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Training R2 Validation R2\n",
            "DT    0.996361      0.795116\n",
            "RF    0.985199      0.922475\n",
            "GB    0.948657      0.905314\n"
          ]
        }
      ],
      "source": [
        "# Split the dataset into a training and validation set\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "# Initialize the models\n",
        "models = {\n",
        "    \"DT\": DecisionTreeRegressor(),\n",
        "    \"RF\": RandomForestRegressor(),\n",
        "    \"GB\": GradientBoostingRegressor()\n",
        "}\n",
        "\n",
        "# Initialize the results DataFrame\n",
        "results = pd.DataFrame(columns=[\"Training R2\", \"Validation R2\"], index=models.keys())\n",
        "\n",
        "# Loop through the models\n",
        "for model_name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Calculate training R2 score\n",
        "    y_train_pred = model.predict(X_train)\n",
        "    train_r2 = r2_score(y_train, y_train_pred)\n",
        "\n",
        "    # Calculate validation R2 score\n",
        "    y_val_pred = model.predict(X_val)\n",
        "    val_r2 = r2_score(y_val, y_val_pred)\n",
        "\n",
        "    # Add R2 score results to the DataFrame\n",
        "    results.loc[model_name, \"Training R2\"] = train_r2\n",
        "    results.loc[model_name, \"Validation R2\"] = val_r2\n",
        "\n",
        "# Print the results DataFrame\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5257a98",
      "metadata": {
        "id": "a5257a98"
      },
      "source": [
        "### Questions (6 marks)\n",
        "1. How do these results compare to the results using a linear model in the previous assignment? Use values.\n",
        "1. Out of the models you tested, which model would you select for this dataset and why?\n",
        "1. If you wanted to increase the accuracy of the tree-based models, what would you do? Provide two suggestions.\n",
        "\n",
        "*ANSWER HERE*\n",
        "\n",
        "\n",
        "\n",
        "1.\n",
        "Regarding Training Mean Squared Error (MSE): In the previous assignment, the linear model yielded an MSE of 107, while the DT, RF, and GB non-linear models produced MSE values of 74, 28, and 28, respectively. Since the MSE is considerably lower for all three non-linear models compared to the linear model, it can be inferred that the non-linear models outperform the linear model on this dataset.\n",
        "\n",
        "When considering the Training R-squared (R2): The linear model resulted in an R2 value of 0.61, whereas the DT, RF, and GB non-linear models achieved R2 values of 0.996, 0.985, and 0.949, respectively. Given that the R2 values for the non-linear models are much closer to 1, it is evident that the non-linear models are better suited for this dataset.\n",
        "\n",
        "2. My choice for this dataset would be the Random Forest model. It demonstrates a good fit to the data with a Training MSE of 28 and an R2 of 0.98. Furthermore, it generalizes well to unseen data, and it strikes an optimal balance between training and validation performance.\n",
        "\n",
        "3.\n",
        "\n",
        "\n",
        "There are two recommendations to enhance the precision of tree-based models:\n",
        "\n",
        "a. Optimization of Hyperparameters:\n",
        "You can boost the accuracy of your tree-based models by optimizing hyperparameters. Utilize techniques such as Grid Search or Random Search to conduct a hyperparameter optimization process, which will help you discover the most suitable combination of hyperparameters for your tree-based models. These hyperparameters encompass parameters like the maximum tree depth, the number of trees (in the case of Random Forest), learning rate (for Gradient Boosting), and others. Adjusting these hyperparameters can yield significant improvements in model accuracy.\n",
        "\n",
        "b. Implementing Regularization:\n",
        "If your tree-based model is prone to overfitting, consider employing regularization techniques. Certain tree-based models, such as Gradient Boosting, offer the option to apply L1 and L2 regularization to mitigate overfitting issues."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37b238f4",
      "metadata": {
        "id": "37b238f4"
      },
      "source": [
        "### Process Description (4 marks)\n",
        "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
        "1. Where did you source your code?\n",
        "1. In what order did you complete the steps?\n",
        "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
        "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93097bfe",
      "metadata": {
        "id": "93097bfe"
      },
      "source": [
        "*DESCRIBE YOUR PROCESS HERE*\n",
        "\n",
        "\n",
        "1. I leveraged the knowledge I gained from my lectures to formulate the core structure of the code and then utilized generative AI assistance to ensure precise syntax.\n",
        "2. I followed the order of the suggested questions when completing them.\n",
        "3. While working with AI, it overlooked certain details, such as setting the random_state to 42 when we were instructed to use 0. As a result, I had to cross-check and make necessary adjustments. Some of the AI prompts included: \"Partition the data into training and validation sets\" and \"Generate a dataframe with columns for Training accuracy and Validation accuracy, indexed by DT, RF, and GB.\"\n",
        "4. I encountered difficulties in selecting the most suitable model for this dataset. While the Decision Tree (DT) performed well on the training dataset, it didn't yield the best validation results. This prompted me to explore further, conducting online research to better understand the process of choosing the right model and resolve this issue."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7c6de86",
      "metadata": {
        "id": "f7c6de86"
      },
      "source": [
        "## Part 2: Classification (17.5 marks)\n",
        "\n",
        "You have been asked to develop code that can help the user classify different wine samples. Following the machine learning workflow described in class, write the relevant code in each of the steps below:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f9d33a8",
      "metadata": {
        "id": "5f9d33a8"
      },
      "source": [
        "### Step 1: Data Input (2 marks)\n",
        "\n",
        "The data used for this task can be downloaded from UCI: https://archive.ics.uci.edu/dataset/109/wine\n",
        "\n",
        "Use the pandas library to load the dataset. You must define the column headers if they are not included in the dataset\n",
        "\n",
        "You will need to split the dataset into feature matrix `X` and target vector `y`. Which column represents the target vector?\n",
        "\n",
        "Print the size and type of `X` and `y`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "33583c67",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33583c67",
        "outputId": "f5c511c5-1558-42a9-ca18-55a7dc6ad1eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of X: (178, 13)\n",
            "Size of y: (178,)\n",
            "Type of X: <class 'pandas.core.frame.DataFrame'>\n",
            "Type of y: <class 'pandas.core.series.Series'>\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd  # Import the pandas library for data manipulation\n",
        "\n",
        "# Define the column headers for the dataset\n",
        "column_headers = [\n",
        "    \"Class\",  # Target variable (wine class)\n",
        "    \"Alcohol\",\n",
        "    \"Malic Acid\",\n",
        "    \"Ash\",\n",
        "    \"Alcalinity of Ash\",\n",
        "    \"Magnesium\",\n",
        "    \"Total Phenols\",\n",
        "    \"Flavanoids\",\n",
        "    \"Nonflavanoid Phenols\",\n",
        "    \"Proanthocyanins\",\n",
        "    \"Color Intensity\",\n",
        "    \"Hue\",\n",
        "    \"OD280/OD315 of Diluted Wines\",\n",
        "    \"Proline\"\n",
        "]\n",
        "\n",
        "# URL of the dataset to be read into a pandas DataFrame\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\"\n",
        "\n",
        "# Read the dataset from the URL and assign column names\n",
        "wine_data = pd.read_csv(url, names=column_headers)\n",
        "\n",
        "# Split the dataset into features (X) and the target variable (y)\n",
        "X = wine_data.drop(\"Class\", axis=1)  # X contains all columns except \"Class\"\n",
        "y = wine_data[\"Class\"]  # y contains the \"Class\" column\n",
        "\n",
        "# Print information about the data\n",
        "print(\"Size of X:\", X.shape)  # Display the dimensions of X\n",
        "print(\"Size of y:\", y.shape)  # Display the dimensions of y\n",
        "print(\"Type of X:\", type(X))  # Display the data type of X (should be a DataFrame)\n",
        "print(\"Type of y:\", type(y))  # Display the data type of y (should be a Series)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "156db208",
      "metadata": {
        "id": "156db208"
      },
      "source": [
        "### Step 2: Data Processing (1.5 marks)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a28af110",
      "metadata": {
        "id": "a28af110"
      },
      "source": [
        "Print the first five rows of the dataset to inspect:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "ea266921",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ea266921",
        "outputId": "fed0eca2-ec44-4654-f75c-9eef33033ef9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Class  Alcohol  Malic Acid   Ash  Alcalinity of Ash  Magnesium  \\\n",
            "0      1    14.23        1.71  2.43               15.6        127   \n",
            "1      1    13.20        1.78  2.14               11.2        100   \n",
            "2      1    13.16        2.36  2.67               18.6        101   \n",
            "3      1    14.37        1.95  2.50               16.8        113   \n",
            "4      1    13.24        2.59  2.87               21.0        118   \n",
            "\n",
            "   Total Phenols  Flavanoids  Nonflavanoid Phenols  Proanthocyanins  \\\n",
            "0           2.80        3.06                  0.28             2.29   \n",
            "1           2.65        2.76                  0.26             1.28   \n",
            "2           2.80        3.24                  0.30             2.81   \n",
            "3           3.85        3.49                  0.24             2.18   \n",
            "4           2.80        2.69                  0.39             1.82   \n",
            "\n",
            "   Color Intensity   Hue  OD280/OD315 of Diluted Wines  Proline  \n",
            "0             5.64  1.04                          3.92     1065  \n",
            "1             4.38  1.05                          3.40     1050  \n",
            "2             5.68  1.03                          3.17     1185  \n",
            "3             7.80  0.86                          3.45     1480  \n",
            "4             4.32  1.04                          2.93      735  \n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(wine_data.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "834fc8fe",
      "metadata": {
        "id": "834fc8fe"
      },
      "source": [
        "Check to see if there are any missing values in the dataset. If necessary, select an appropriate method to fill-in the missing values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "97c6e9dc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97c6e9dc",
        "outputId": "9f277ee5-d5f7-4f46-e564-22f8cfda88bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing Values:\n",
            " Class                           0\n",
            "Alcohol                         0\n",
            "Malic Acid                      0\n",
            "Ash                             0\n",
            "Alcalinity of Ash               0\n",
            "Magnesium                       0\n",
            "Total Phenols                   0\n",
            "Flavanoids                      0\n",
            "Nonflavanoid Phenols            0\n",
            "Proanthocyanins                 0\n",
            "Color Intensity                 0\n",
            "Hue                             0\n",
            "OD280/OD315 of Diluted Wines    0\n",
            "Proline                         0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# This code calculates the number of missing values in each column of the 'wine_data' DataFrame.\n",
        "# It uses the 'isnull()' method to identify missing values and 'sum()' to count them.\n",
        "\n",
        "missing_values = wine_data.isnull().sum()\n",
        "\n",
        "# This line prints out the count of missing values for each column.\n",
        "print(\"Missing Values:\\n\", missing_values)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "070956af",
      "metadata": {
        "id": "070956af"
      },
      "source": [
        "How many samples do we have of each type of wine?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "b37a6fd9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b37a6fd9",
        "outputId": "34e93f94-5938-4787-f12f-b6a491370754"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples for each type of wine:\n",
            "2    71\n",
            "1    59\n",
            "3    48\n",
            "Name: Class, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# This code calculates the count of each unique value in the \"Class\" column of the 'wine_data' DataFrame.\n",
        "wine_counts = wine_data[\"Class\"].value_counts()\n",
        "\n",
        "# Printing the number of samples for each type of wine.\n",
        "print(\"Number of samples for each type of wine:\")\n",
        "# Printing the counts for each unique value in the \"Class\" column.\n",
        "print(wine_counts)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70e6c46f",
      "metadata": {
        "id": "70e6c46f"
      },
      "source": [
        "### Step 3: Implement Machine Learning Model\n",
        "\n",
        "1. Import `SVC` and `DecisionTreeClassifier` from sklearn\n",
        "2. Instantiate models as `SVC()` and `DecisionTreeClassifier(max_depth = 3)`\n",
        "3. Implement the machine learning model with `X` and `y`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0870b0d2",
      "metadata": {
        "id": "0870b0d2"
      },
      "source": [
        "### Step 4: Validate Model\n",
        "\n",
        "Calculate the average training and validation accuracy using `cross_validate` for the two different models listed in Step 3. For this case, use `scoring='accuracy'`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb0bbd83",
      "metadata": {
        "id": "bb0bbd83"
      },
      "source": [
        "### Step 5: Visualize Results (4 marks)\n",
        "\n",
        "#### Step 5.1: Compare Models\n",
        "1. Create a pandas DataFrame `results` with columns: Training accuracy and Validation accuracy\n",
        "2. Add the data size, training and validation accuracy for each dataset to the `results` DataFrame\n",
        "3. Print `results`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "be4b5c0a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "be4b5c0a",
        "outputId": "2f5c3f9e-3c6c-4b59-966c-e2aceb0d61f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Comparison Results:\n",
            "               Data Size  Training Accuracy  Validation Accuracy\n",
            "SVC                178.0           0.703743             0.663492\n",
            "Decision Tree      178.0           0.974756             0.882063\n"
          ]
        }
      ],
      "source": [
        "# Import necessary modules for building machine learning models.\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Create an instance of Support Vector Machine (SVC) and Decision Tree Classifier models.\n",
        "svc_model = SVC()\n",
        "dt_model = DecisionTreeClassifier(max_depth=3)\n",
        "\n",
        "# Fit the SVC and Decision Tree models to the data (X and y).\n",
        "svc_model.fit(X, y)\n",
        "dt_model.fit(X, y)\n",
        "\n",
        "# Perform cross-validation for the SVC and Decision Tree models, scoring them on accuracy.\n",
        "svc_scores = cross_validate(svc_model, X, y, scoring='accuracy', return_train_score=True)\n",
        "dt_scores = cross_validate(dt_model, X, y, scoring='accuracy', return_train_score=True)\n",
        "\n",
        "# Calculate the mean training and validation accuracy for the SVC and Decision Tree models.\n",
        "svc_train_accuracy = svc_scores['train_score'].mean()\n",
        "svc_val_accuracy = svc_scores['test_score'].mean()\n",
        "dt_train_accuracy = dt_scores['train_score'].mean()\n",
        "dt_val_accuracy = dt_scores['test_score'].mean()\n",
        "\n",
        "# Create an empty DataFrame to store the model comparison results.\n",
        "results = pd.DataFrame(columns=[\"Data Size\", \"Training Accuracy\", \"Validation Accuracy\"])\n",
        "\n",
        "# Populate the results DataFrame with the information for the SVC and Decision Tree models.\n",
        "results.loc[\"SVC\"] = [len(X), svc_train_accuracy, svc_val_accuracy]\n",
        "results.loc[\"Decision Tree\"] = [len(X), dt_train_accuracy, dt_val_accuracy]\n",
        "\n",
        "# Print the model comparison results.\n",
        "print(\"Model Comparison Results:\")\n",
        "print(results)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2e17878",
      "metadata": {
        "id": "f2e17878"
      },
      "source": [
        "#### Step 5.2: Visualize Classification Errors\n",
        "Which method gave the highest accuracy? Use this method to print the confusion matrix and classification report:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "44b091a4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44b091a4",
        "outputId": "7a54d819-c9ad-4790-f9db-4f88e31024aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The method with the highest accuracy is: Decision Tree\n",
            "Validation Accuracy of the best model: 0.8876190476190476\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Determine the best model based on validation accuracy.\n",
        "# If Support Vector Classifier (SVC) has a higher accuracy,\n",
        "\n",
        "best_model = \"SVC\" if svc_val_accuracy > dt_val_accuracy else \"Decision Tree\"\n",
        "\n",
        "# Print the best model found based on validation accuracy.\n",
        "print(f\"The method with the highest accuracy is: {best_model}\")\n",
        "\n",
        "# Print the validation accuracy of the best model.\n",
        "\n",
        "print(f\"Validation Accuracy of the best model: {svc_val_accuracy if best_model == 'SVC' else dt_val_accuracy}\")\n",
        "\n",
        "# If the best model is \"SVC,\" make predictions using the SVC model;\n",
        "# otherwise, make predictions using the Decision Tree model.\n",
        "if best_model == \"SVC\":\n",
        "    y_pred = svc_model.predict(X)\n",
        "else:\n",
        "    y_pred = dt_model.predict(X)\n",
        "\n",
        "# Calculate the confusion matrix (cm) and classification report (cr)\n",
        "\n",
        "cm = confusion_matrix(y, y_pred)\n",
        "cr = classification_report(y, y_pred, target_names=wine_counts.index.astype(str).tolist())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "09d21b59",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        },
        "id": "09d21b59",
        "outputId": "d9940406-c98a-4da7-d509-c1eda278463a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "\n",
        "# TO DO: Print confusion matrix using a heatmap\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=wine_counts.index, yticklabels=wine_counts.index)\n",
        "\n",
        "\n",
        "plt.xlabel('Predicted')\n",
        "\n",
        "plt.ylabel('Actual')\n",
        "\n",
        "plt.title('Confusion Matrix')\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "5ef95947",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ef95947",
        "outputId": "4ce6e031-b96c-4f8a-d600-53dde1ab0261"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report for the best model:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           2       1.00      0.97      0.98        59\n",
            "           1       0.96      0.99      0.97        71\n",
            "           3       0.98      0.98      0.98        48\n",
            "\n",
            "    accuracy                           0.98       178\n",
            "   macro avg       0.98      0.98      0.98       178\n",
            "weighted avg       0.98      0.98      0.98       178\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# TO DO: Print classification report\n",
        "\n",
        "# Predict the target values based on the best model (SVC or Decision Tree).\n",
        "y_pred = svc_model.predict(X) if best_model == \"SVC\" else dt_model.predict(X)\n",
        "\n",
        "# Generate a classification report based on the true labels (y) and the predicted labels (y_pred).\n",
        "report = classification_report(y, y_pred, target_names=wine_counts.index.astype(str).tolist())\n",
        "\n",
        "# Print the classification report for the best model.\n",
        "print(\"Classification Report for the best model:\")\n",
        "print(report)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf319621",
      "metadata": {
        "id": "bf319621"
      },
      "source": [
        "### Questions (6 marks)\n",
        "1. How do the training and validation accuracy change depending on the method used? Explain with values.\n",
        "1. What are two reasons why the support vector machines model did not work as well as the tree-based model?\n",
        "1. How many samples were incorrectly classified in step 5.2?\n",
        "1. In this case, is maximizing precision or recall more important? Why?\n",
        "\n",
        "*YOUR ANSWERS HERE*\n",
        "\n",
        "\n",
        "1. SVMs encounter difficulties when dealing with intricate, non-linear datasets, especially when the data lacks clear separation or when the decision boundary isn't easily defined by a hyperplane. The performance of SVMs can also vary significantly depending on the choice of hyperparameters. Improperly tuned hyperparameters can result in suboptimal model performance.\n",
        "\n",
        "2.\n",
        "\n",
        " The Decision Tree Classifier exhibits superior training and validation accuracy in comparison to the SVC. This implies that the Decision Tree model effectively captures intricate data patterns and generalizes well to new, unseen data.\n",
        "\n",
        "3. To ascertain the count of misclassified samples, you can calculate the complementary value to the accuracy.\n",
        "Number of misclassified samples = Total samples - Correctly classified samples\n",
        "Number of misclassified samples = 178 - (178 * 0.98)\n",
        "Number of misclassified samples = 3.56\n",
        "As it's impossible to have a fraction of a sample being misclassified, this indicates that 3 samples were inaccurately classified.\n",
        "\n",
        "4. In this dataset, we observe high precision and recall values for each class, indicating the model's strong performance. In this scenario, false positives have a lower impact, and therefore, the emphasis should be on maximizing recall."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "664ff8ae",
      "metadata": {
        "id": "664ff8ae"
      },
      "source": [
        "### Process Description (4 marks)\n",
        "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
        "1. Where did you source your code?\n",
        "1. In what order did you complete the steps?\n",
        "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
        "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0e837da",
      "metadata": {
        "id": "d0e837da"
      },
      "source": [
        "*DESCRIBE YOUR PROCESS HERE*\n",
        "\n",
        "1. I applied the concepts from lectures to formulate the basic structure of the code, and then enlisted the assistance of generative AIs to refine the exact syntax.\n",
        "2. I tackled the questions in the sequence recommended within the provided questions.\n",
        "3. I relied on AI to suggest column headers based on the data, although it wasn't entirely accurate. I needed to revisit the data and rectify the titles for three columns.\n",
        "4. Determining whether to prioritize maximizing recall or precision in the preceding section posed a challenge, as discerning between a false negative and false positive was often ambiguous in this particular application."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4cd7358d",
      "metadata": {
        "id": "4cd7358d"
      },
      "source": [
        "## Part 3: Observations/Interpretation (3 marks)\n",
        "\n",
        "Describe any pattern you see in the results. Relate your findings to what we discussed during lectures. Include data to justify your findings.\n",
        "\n",
        "\n",
        "*ADD YOUR FINDINGS HERE*\n",
        "\n",
        "\n",
        "\n",
        "Question 1: Although training model R2 exhibits promising results, such as an R2 of 0.996 for DT, it doesn't guarantee good validation and generalization for the data. Hence, it is crucial to possess a representative dataset and assess the model's performance across various datasets.\n",
        "\n",
        "Question 2: F1-Score: The F1-score, which is the harmonic mean of precision and recall, achieves a balance between these two metrics. Across all classes (1, 2, and 3), the F1-scores are notably high, demonstrating a well-balanced trade-off between precision and recall.\n",
        "\n",
        "Macro Avg: The macro average represents the unweighted average of precision, recall, and F1-score across all classes. In this instance, the macro average stands at 0.98, signifying the model's strong performance across all classes.\n",
        "\n",
        "Precision & Recall: Precision quantifies the model's accuracy in making positive predictions, while recall (also known as sensitivity or true positive rate) assesses the model's ability to identify all relevant instances. In our dataset, both precision and recall exhibit exceptionally high values, indicating that the model is an excellent fit for this data."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd97b6ac",
      "metadata": {
        "id": "cd97b6ac"
      },
      "source": [
        "## Part 4: Reflection (2 marks)\n",
        "Include a sentence or two about:\n",
        "- what you liked or disliked,\n",
        "- found interesting, confusing, challangeing, motivating\n",
        "while working on this assignment.\n",
        "\n",
        "\n",
        "I appreciated the assignment's structured approach, which effectively guided me towards finding the answers. If the question had presented a single, broad task of identifying a suitable model, I believe it would have posed a challenge for me. However, by breaking down the problem into sequential steps, beginning with calculating MSE values, then R2 values, creating heat maps, and ultimately instructing us to compare the best models, it made the task more manageable.\n",
        "\n",
        "I found the theoretical and deductive aspects following the coding to be engaging. Unlike many other courses where coding dominates, the inclusion of theory allows us to gain a deeper understanding of the purpose of the code and its relevance in real-world applications. This theoretical component enhances our ability to connect theory to practical implementation.\n",
        "*ADD YOUR THOUGHTS HERE*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa21e53b",
      "metadata": {
        "id": "fa21e53b"
      },
      "source": [
        "## Part 5: Bonus Question (3 marks)\n",
        "\n",
        "Repeat Part 2 and compare the support vector machines model used to `LinearSVC(max_iter=5000)`. Does using `LinearSVC` improve the results? Why or why not?\n",
        "\n",
        "Is `LinearSVC` a good fit for this dataset? Why or why not?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "30fea72e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30fea72e",
        "outputId": "f3c95b2a-fc4f-4293-ae69-3969a49ee4fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                  Training Accuracy Validation Accuracy\n",
            "Decision Tree                   1.0            0.944444\n",
            "Random Forest                   1.0                 1.0\n",
            "Gradient Boosting               1.0            0.944444\n",
            "LinearSVC                  0.915493            0.972222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from yellowbrick.classifier import ClassificationReport\n",
        "\n",
        "# Data Source\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\"\n",
        "column_names = [\n",
        "    \"Class\",\n",
        "    \"Alcohol\",\n",
        "    \"Malic acid\",\n",
        "    \"Ash\",\n",
        "    \"Alcalinity of ash\",\n",
        "    \"Magnesium\",\n",
        "    \"Total phenols\",\n",
        "    \"Flavanoids\",\n",
        "    \"Nonflavanoid phenols\",\n",
        "    \"Proanthocyanins\",\n",
        "    \"Color intensity\",\n",
        "    \"Hue\",\n",
        "    \"OD280/OD315 of diluted wines\",\n",
        "    \"Proline\"\n",
        "]\n",
        "data = pd.read_csv(url, names=column_names)\n",
        "\n",
        "# Splitting Data\n",
        "X = data.drop(\"Class\", axis=1)\n",
        "y = data[\"Class\"]\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Models\n",
        "models = {\n",
        "    \"Decision Tree\": DecisionTreeClassifier(),\n",
        "    \"Random Forest\": RandomForestClassifier(),\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
        "    \"LinearSVC\": LinearSVC(max_iter=5000)\n",
        "}\n",
        "\n",
        "# Model Evaluation\n",
        "results = pd.DataFrame(columns=[\"Training Accuracy\", \"Validation Accuracy\"], index=models.keys())\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    y_train_pred = model.predict(X_train)\n",
        "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "\n",
        "    y_val_pred = model.predict(X_val)\n",
        "    val_accuracy = accuracy_score(y_val, y_val_pred)\n",
        "\n",
        "    results.loc[model_name, \"Training Accuracy\"] = train_accuracy\n",
        "    results.loc[model_name, \"Validation Accuracy\"] = val_accuracy\n",
        "\n",
        "# Display Results\n",
        "print(results)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aabc68a4",
      "metadata": {
        "id": "aabc68a4"
      },
      "source": [
        "*ANSWER HERE*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "241c3b12",
      "metadata": {
        "id": "241c3b12"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}